---
version: "3.7"
name: dataworks
services:
  broker:
    image: docker.redpanda.com/redpandadata/redpanda:latest
    container_name: broker
    command:
      - redpanda
      - start
      - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092
      - --advertise-kafka-addr internal://broker:9092,external://localhost:19092
      - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082
      - --advertise-pandaproxy-addr internal://broker:8082,external://localhost:18082
      - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
      - --rpc-addr broker:33145
      - --advertise-rpc-addr broker:33145
      - --smp 1
      - --memory 1G
      - --mode dev-container
      - --default-log-level=error
    volumes:
      - broker:/var/lib/redpanda/data
    ports:
      - 18081:18081
      - 18082:18082
      - 19092:19092
      - 19644:9644
    networks:
      - dataworks
    profiles:
      - base
      - kafka
  console:
    container_name: console
    image: docker.redpanda.com/vectorized/console:v2.2.2
    entrypoint: /bin/sh
    command: -c 'echo "$$CONSOLE_CONFIG_FILE" > /tmp/config.yml; /app/console'
    environment: 
      CONFIG_FILEPATH: /tmp/config.yml
      CONSOLE_CONFIG_FILE: |
        kafka:
          brokers: ["broker:9092"]
          schemaRegistry:
            enabled: true
            urls: ["http://broker:8081"]
        redpanda:
          adminApi:
            enabled: true
            urls: ["http://broker:9644"]
        connect:
          enabled: true
          clusters:
            - name: local-connect-cluster
              url: http://connect:8083
    ports:
      - "8080:8080"
    networks:
      - dataworks
    profiles:
      - base
      - kafka
    depends_on:
      - broker
  connect:
    image: docker.redpanda.com/redpandadata/connectors:latest
    platform: 'linux/amd64'
    hostname: connect
    container_name: connect
    environment:
      CONNECT_CONFIGURATION: |
          key.converter=org.apache.kafka.connect.converters.ByteArrayConverter
          value.converter=org.apache.kafka.connect.converters.ByteArrayConverter
          group.id=connectors-cluster
          offset.storage.topic=_internal_connectors_offsets
          config.storage.topic=_internal_connectors_configs
          status.storage.topic=_internal_connectors_status
          config.storage.replication.factor=-1
          offset.storage.replication.factor=-1
          status.storage.replication.factor=-1
          offset.flush.interval.ms=1000
          producer.linger.ms=50
          producer.batch.size=131072
      CONNECT_BOOTSTRAP_SERVERS: broker:9092
      CONNECT_GC_LOG_ENABLED: "false"
      CONNECT_HEAP_OPTS: -Xms512M -Xmx512M
      CONNECT_LOG_LEVEL: info
      AWS_ACCESS_KEY_ID: "minio"
      AWS_SECRET_ACCESS_KEY: "minio123"
    volumes:
      - ${PWD}/connect/plugins/confluentinc-kafka-connect-elasticsearch:/opt/kafka/redpanda-plugins/confluentinc-kafka-connect-elasticsearch
      - ${PWD}/connect/plugins/confluentinc-kafka-connect-datagen:/opt/kafka/redpanda-plugins/confluentinc-kafka-connect-datagen
      - ${PWD}/connect/plugins/confluentinc-kafka-connect-s3:/opt/kafka/redpanda-plugins/confluentinc-kafka-connect-s3
      - ${PWD}/connect/plugins/camel-aws-s3-sink-kafka-connector:/opt/kafka/redpanda-plugins/camel-aws-s3-sink-kafka-connector
      - ${PWD}/connect/plugins/camel-aws-s3-source-kafka-connector:/opt/kafka/redpanda-plugins/camel-aws-s3-source-kafka-connector
      - ${PWD}/connect/plugins/camel-aws-s3-streaming-upload-sink-kafka-connector:/opt/kafka/redpanda-plugins/camel-aws-s3-streaming-upload-sink-kafka-connector
    ports:
      - "8083:8083"
    networks:
      - dataworks
    profiles:
      - connect
      - kafka
  elastic-01:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.6.2
    hostname: elastic-01
    container_name: elastic-01
    environment:
      - node.name=elastic-01
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=elastic-02,elastic-03
      - cluster.initial_master_nodes=elastic-01,elastic-02,elastic-03
      - bootstrap.memory_lock=true
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    networks:
      - dataworks
    profiles:
      - elasticsearch
  elastic-02:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.6.2
    hostname: elastic-02
    container_name: elastic-02
    environment:
      - node.name=elastic-02
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=elastic-01,elastic-03
      - cluster.initial_master_nodes=elastic-01,elastic-02,elastic-03
      - bootstrap.memory_lock=true
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata02:/usr/share/elasticsearch/data
    networks:
      - dataworks
    profiles:
      - elasticsearch
  elastic-03:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.6.2
    hostname: elastic-03
    container_name: elastic-03
    environment:
      - node.name=elastic-03
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=elastic-01,elastic-02
      - cluster.initial_master_nodes=elastic-01,elastic-02,elastic-03
      - bootstrap.memory_lock=true
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata03:/usr/share/elasticsearch/data
    networks:
      - dataworks
    profiles:
      - elasticsearch
  kibana:
    image: docker.elastic.co/kibana/kibana:8.6.2
    container_name: kibana
    environment:
      SERVER_NAME: 127.0.0.1
      ELASTICSEARCH_HOSTS: '["http://elastic-01:9200","http://elastic-02:9200","http://elastic-03:9200","http://es04:9200"]'
      # XPACK_GRAPH_ENABLED: false
      # XPACK_ML_ENABLED: false
      # XPACK_REPORTING_ENABLED: false
      # XPACK_SECURITY_ENABLED: false
      # XPACK_WATCHER_ENABLED: false
    restart: "unless-stopped"
    ports:
      - "5601:5601"
    networks:
      - dataworks
    profiles:
      - elasticsearch
    depends_on:
      - elastic-01
      - elastic-02
      - elastic-03
  s3:
    image: quay.io/minio/minio:RELEASE.2023-03-20T20-16-18Z
    container_name: s3
    command: server --console-address ":9001" /data/minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    volumes:
      - s3:/data
    networks:
      - dataworks
    profiles:
      - s3
  flink-jobmanager:
    image: flink:latest
    container_name: flink-jobmanager
    hostname: flink-jobmanager
    command: jobmanager
    ports:
      - "8081:8081"
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager 
    networks:
      - dataworks
    profiles:
      - flink
  flink-taskmanager:
    image: flink:latest
    container_name: flink-taskmanager
    hostname: flink-taskmanager
    command: taskmanager
    depends_on:
      - flink-jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2     
    networks:
      - dataworks
    profiles:
      - flink
  flink-sql:
    image: flink:latest
    container_name: flink-sql
    hostname: flink-sql
    command: bin/sql-client.sh
    depends_on:
      - flink-jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        rest.address: flink-jobmanager
    networks:
      - dataworks
    profiles:
      - flink
  qw-ingest:
    image: quickwit/quickwit
    container_name: qw-ingest
    hostname: qw-ingest
    profiles:
      - quickwit
  qw-query:
    image: quickwit/quickwit
    container_name: qw-query
    hostname: qw-query
    profiles:
      - quickwit
  postgres:
    image: postgres
    container_name: postgres
    hostname: postgres
    profiles:
      - quickwit
      - superset
  redis:
    image: redis:latest
    container_name: redis
    hostname: redis
    profiles:
      - quickwit
      - superset
      - monitoring
    ports:
      - "6379:6379"
    networks:
      - dataworks
  superset:
    image: superset
    profiles:
      - superset
  prometheus:
    image: prom/prometheus
    container_name: prometheus
    hostname: prometheus
    profiles:
      - monitoring
    volumes:
      - $PWD/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    depends_on:
      - cadvisor
    ports:
      - "9090:9090"
    networks:
      - dataworks
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.45.0
    privileged: true
    container_name: cadvisor
    hostname: cadvisor
    profiles:
      - monitoring
    volumes:
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /etc/machine-id:/etc/machine-id:ro
      - /var/lib/dbus/machine-id:/var/lib/dbus/machine-id:ro
    devices:
      - /dev/kmsg:/dev/kmsg
    depends_on:
      - redis
    expose:
      - 8080
    ports:
      - "8081:8080"
    networks:
      - dataworks
volumes:
  esdata01:
    driver: local
  esdata02:
    driver: local
  esdata03:
    driver: local
  broker: null
  s3:
    driver: local
networks:
  dataworks:
    driver: bridge
